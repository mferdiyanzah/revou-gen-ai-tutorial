{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71024a1b",
   "metadata": {},
   "source": [
    "# Lab 4: Building an AI Agent with Langgraph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e1d012",
   "metadata": {},
   "source": [
    "## LangGraph \n",
    "Langgraph is a low-level orchestration framework for building controllable agents. While langchain provides integrations and composable components to streamline LLM application development, the LangGraph library enables **agent orchestration** — offering customizable architectures, long-term memory, and human-in-the-loop to reliably handle complex tasks.\n",
    "\n",
    "## Initiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21f08dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installing langgraph package\n",
    "!pip install langgraph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07024fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading environment variables \n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)  # take environment variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed7c482",
   "metadata": {},
   "source": [
    "## Learning about Graph\n",
    "\n",
    "Let's examine the simplest form of a graph as used in LangGraph. <br /><br />\n",
    "<img src=\"./assets/simple graph.png\" width=\"450\">\n",
    "\n",
    "A LangGraph graph is composed of the following components:\n",
    "1. State: The state represents the shared memory or context that flows through the graph. It is typically a structured data object (e.g., a dictionary or class) that holds intermediate inputs, outputs, and metadata across the graph's execution. The state is updated as it moves from node to node.\n",
    "\n",
    "2. Node: A node represents a unit of computation — usually a function, language model call, or tool execution. Each node operates on the incoming state, performs some processing, and returns an updated state. Nodes are the core logic blocks in LangGraph.\n",
    "\n",
    "3. Edge: An edge defines the transition between nodes. It determines which node to execute next based on the current state or the output of the previous node. Edges can be static (predefined paths) or dynamic (based on conditions or branching logic), enabling flexible and adaptive workflows.\n",
    "\n",
    "### State, Nodes, and Edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23117b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# State\n",
    "from typing import TypedDict, Literal\n",
    "\n",
    "class State(TypedDict):\n",
    "    user_selection: str\n",
    "    graph_state: str\n",
    "\n",
    "# Nodes\n",
    "# Nodes are just python functions. Each node operates on the state.\n",
    "# Langgraph has 2 special nodes, called START node and END, to denote the start and the end of a graph.\n",
    "\n",
    "def node1(state):\n",
    "    print(\"---Inside Node No 1---\")\n",
    "    return {'graph_state': state['graph_state'] + \"Passing through Node 1. | \"}\n",
    "\n",
    "def node2(state):\n",
    "    print(\"---Inside Node No 2---\")\n",
    "    return {'graph_state': state['graph_state'] + \"Passing through Node 2. | \"}\n",
    "\n",
    "def node3(state):\n",
    "    print(\"---Inside Node No 3---\")\n",
    "    return {'graph_state': state['graph_state'] + \"Passing through Node 3. | \"}\n",
    "\n",
    "# Edges\n",
    "# 2 types of edges: normal edges vs conditional edges\n",
    "# Normal edges will be defined directly when we build the graph using langgraph\n",
    "# Conditional edges require a function to define the conditions\n",
    "# Here we will define an example of conditional edges\n",
    "\n",
    "def decide_your_way(state) -> Literal[\"Node2\", \"Node3\"]:\n",
    "    user_selection = state['user_selection']\n",
    "\n",
    "    if user_selection == \"Node 2\":\n",
    "        return \"Node2\"\n",
    "    else:\n",
    "        return \"Node3\"\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de03a6c1",
   "metadata": {},
   "source": [
    "### Graph Construction\n",
    "Let's connect those nodes into a graph using StateGraph from LangGraph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b202af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "# Build the nodes\n",
    "builder = StateGraph(State)\n",
    "builder.add_node(\"Node1\", node1)\n",
    "builder.add_node(\"Node2\", node2)\n",
    "builder.add_node(\"Node3\", node3)\n",
    "\n",
    "# Connect Edges\n",
    "builder.add_edge(START, \"Node1\")\n",
    "builder.add_conditional_edges(\"Node1\", decide_your_way)\n",
    "builder.add_edge(\"Node2\", END)\n",
    "builder.add_edge(\"Node3\", END)\n",
    "\n",
    "# Compile graph\n",
    "graph = builder.compile()\n",
    "\n",
    "# View\n",
    "from IPython.display import Image, display\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c3f58f",
   "metadata": {},
   "source": [
    "### Graph Invocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a229ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph invocation\n",
    "user_input = input(\"Decide which way you want to go (Node 2 or Node 3): \")\n",
    "graph.invoke({'user_selection': user_input, 'graph_state': \"START | \"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6c461f",
   "metadata": {},
   "source": [
    "## State Schema\n",
    "\n",
    "When you initiate a builder in LangGraph, you need to provide the schema of the graph's state to the StateGraph class. This schema defines the structure and data types of the state. Previously, the schema was created using the TypedDict class, but it can also be defined using Python's dataclass or the Pydantic library. Using Pydantic allows you to enforce type validation, offering better protection for the state's parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a22aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previous schema, but we put limitation on user_selection parameter to only valid for 2 values only\n",
    "class TypedDictState(TypedDict):\n",
    "    user_selection: Literal[\"Node 2\", \"Node 3\"]\n",
    "    graph_state: str\n",
    "\n",
    "# modify the conditional node \n",
    "def choose_paths(state):\n",
    "    user_selection = state['user_selection']\n",
    "\n",
    "    if user_selection == \"Node 2\":\n",
    "        return \"Node2\"\n",
    "    elif user_selection == \"Node 3\":\n",
    "        return \"Node3\"\n",
    "    else: \n",
    "        return END\n",
    "\n",
    "# Build the nodes\n",
    "builder = StateGraph(TypedDictState)\n",
    "builder.add_node(\"Node1\", node1)\n",
    "builder.add_node(\"Node2\", node2)\n",
    "builder.add_node(\"Node3\", node3)\n",
    "\n",
    "# Connect Edges\n",
    "builder.add_edge(START, \"Node1\")\n",
    "builder.add_conditional_edges(\"Node1\", choose_paths)\n",
    "builder.add_edge(\"Node2\", END)\n",
    "builder.add_edge(\"Node3\", END)\n",
    "\n",
    "# Compile graph\n",
    "graph2 = builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36576db",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = input(\"Decide which way you want to go (Node 2 or Node 3): \")\n",
    "graph2.invoke({'user_selection': user_input, 'graph_state': \"START | \"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec3dc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pydantic\n",
    "from langchain_core.pydantic_v1 import BaseModel, ValidationError\n",
    "\n",
    "class PydanticState(BaseModel):\n",
    "    user_selection: Literal[\"Node 2\", \"Node 3\"]\n",
    "    graph_state: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a74a3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PydanticState(user_selection=\"Node 4\", graph_state=3) \n",
    "PydanticState(user_selection=\"Node 2\", graph_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbf87cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = PydanticState(user_selection=\"Node 2\", graph_state=\"fi\") \n",
    "a.user_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6beb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the nodes\n",
    "def node1(state):\n",
    "    print(\"---Inside Node No 1---\")\n",
    "    return {'graph_state': state.graph_state + \"Passing through Node 1. | \"}\n",
    "\n",
    "def node2(state):\n",
    "    print(\"---Inside Node No 2---\")\n",
    "    return {'graph_state': state.graph_state + \"Passing through Node 2. | \"}\n",
    "\n",
    "def node3(state):\n",
    "    print(\"---Inside Node No 3---\")\n",
    "    return {'graph_state': state.graph_state + \"Passing through Node 3. | \"}\n",
    "\n",
    "def choose_paths(state):\n",
    "    user_selection = state.user_selection\n",
    "\n",
    "    if user_selection == \"Node 2\":\n",
    "        return \"Node2\"\n",
    "    elif user_selection == \"Node 3\":\n",
    "        return \"Node3\"\n",
    "    else: \n",
    "        return END\n",
    "    \n",
    "builder = StateGraph(PydanticState)\n",
    "builder.add_node(\"Node1\", node1)\n",
    "builder.add_node(\"Node2\", node2)\n",
    "builder.add_node(\"Node3\", node3)\n",
    "\n",
    "# Connect Edges\n",
    "builder.add_edge(START, \"Node1\")\n",
    "builder.add_conditional_edges(\"Node1\", choose_paths)\n",
    "builder.add_edge(\"Node2\", END)\n",
    "builder.add_edge(\"Node3\", END)\n",
    "\n",
    "# Compile graph\n",
    "graph3 = builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1da6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = input(\"Decide which way you want to go (Node 2 or Node 3): \")\n",
    "\n",
    "graph_state = None\n",
    "try: \n",
    "    graph_state = graph3.invoke({'user_selection': user_input, 'graph_state': \"START | \"})\n",
    "except ValidationError as e:\n",
    "    print(e)\n",
    "\n",
    "print(graph_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd4e88a",
   "metadata": {},
   "source": [
    "## Message Reducers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181ee87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MessagesState \n",
    "# Built-in state for working with messages \n",
    "\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "# Append Messages into the state\n",
    "initial_state = [AIMessage(content=\"Hello, How can I help you?\", name = \"GPT\"),\n",
    "                 HumanMessage(content=\"I'm learning about generative AI, please explain about it.\", name = \"Hizkia\")\n",
    "                 ]\n",
    "\n",
    "new_message = AIMessage(content=\"Sure, I can help you with that. Here is a brief explanation about generative AI. Generative AI is.... \", name = \"GPT4\")\n",
    "\n",
    "# append\n",
    "add_messages(initial_state, new_message)\n",
    "\n",
    "# the MessagesState Class has embedded add_messages function so a new message will be automatically appended into the state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280c26e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rewriting Messages \n",
    "# use id \n",
    "\n",
    "initial_state = [AIMessage(content=\"Hello, How can I help you?\", name = \"GPT\", id = 1),\n",
    "                 HumanMessage(content=\"I'm learning about generative AI, please explain about it.\", name = \"Hizkia\", id = 2)\n",
    "                 ]\n",
    "\n",
    "new_message = HumanMessage(content=\"I am looking for definition of agentic AI.\", name = \"GPT4\", id = 2)\n",
    "\n",
    "add_messages(initial_state, new_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e967974c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deleting Messages \n",
    "\n",
    "from langchain_core.messages import RemoveMessage\n",
    "\n",
    "# Message List \n",
    "messages = [AIMessage(content=\"Hi, My name is ChatGPT. How may I help you?\", name=\"Bot\", id=1)]\n",
    "messages.append(HumanMessage(content=\"Hi.\", name=\"Hizkia\", id=2))\n",
    "messages.append(AIMessage(content=\"So you said you were looking for information on agentic AI?\", name=\"Bot\", id=3))\n",
    "messages.append(HumanMessage(content=\"Yes, can u provide the brief definition of the term agentic AI?\", name=\"Bot\", id=4))\n",
    "\n",
    "# Delete all but the 2 most recent messages\n",
    "delete_messages = [RemoveMessage(id=m.id) for m in messages[:-2]]\n",
    "print(delete_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7d0a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_messages(messages, delete_messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f1bad7",
   "metadata": {},
   "source": [
    "## MessagesState as a state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12069dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiating Langchain Chat Models\n",
    "from langchain.chat_models import init_chat_model\n",
    "model = init_chat_model(\"gpt-4.1-mini\", model_provider= \"openai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60d0cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import MessagesState\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "# Node to invoke an LLM\n",
    "def call_llm(state: MessagesState):\n",
    "    return {\"messages\": model.invoke(state['messages'])}\n",
    "\n",
    "# build the graph \n",
    "builder = StateGraph(MessagesState)\n",
    "builder.add_node(\"call_llm\", call_llm)\n",
    "\n",
    "builder.add_edge(START, \"call_llm\")\n",
    "builder.add_edge(\"call_llm\", END)\n",
    "graph = builder.compile()\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67525de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "output = graph.invoke({'messages': HumanMessage(content=\"Hi\", name = \"Hizkia\")})\n",
    "\n",
    "for m in output['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87e3a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = graph.invoke({'messages': HumanMessage(content=\"Can you explain about agentic AI?\", name = \"Hizkia\")})\n",
    "\n",
    "for m in output['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f7e11f",
   "metadata": {},
   "source": [
    "## Chaining\n",
    "Let us recreate prompt chaining that we did in Lab 1b, now using Langgraph, instead of using Langchain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0485c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here the graph receives an input text, and generates 3 questions and answers based on the input text.\n",
    "\n",
    "from langgraph.graph import MessagesState\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "\n",
    "input_text = \"\"\"\n",
    "Artificial Intelligence (AI) is transforming industries by enabling machines to learn from data, \n",
    "make decisions, and even improve over time. Applications range from chatbots and virtual assistants \n",
    "to complex data analytics and autonomous vehicles. However, AI also brings challenges such as ethical concerns, \n",
    "bias in algorithms, and job displacement. As AI continues to evolve, balancing innovation with responsible \n",
    "development will be key to its long-term success.\n",
    "\"\"\"\n",
    "\n",
    "# The first node in the chain\n",
    "def summarize(state: MessagesState):\n",
    "    \"\"\"\n",
    "        This tool is called when the user instructs assistant to summarize the passage. Make sure the passage is given by the user before calling this tool. \n",
    "        Ask the user to provide the passage first if you do not find the passage in the conversation. \n",
    "\n",
    "        Receiving the state of the graph as input.\n",
    "    \"\"\"\n",
    "    prompt = [\n",
    "        SystemMessage(content=\"Summarize the following passage from the user.\")\n",
    "    ] +  state['messages']\n",
    "\n",
    "    response = model.invoke(prompt)\n",
    "\n",
    "    return {'messages': AIMessage(content=response.content, name=\"Bot\", id=response.id)}\n",
    "\n",
    "# The second node in the chain\n",
    "def generate_questions(state: MessagesState):\n",
    "    \"\"\" \n",
    "        This tool is called to generate 3 questions related to a passage. Make sure the passage is given by the user before calling this tool. \n",
    "        Ask the user to provide the passage first if you do not find the passage in the conversation. \n",
    "\n",
    "        Receiving the state of the graph as input.\n",
    "    \"\"\"\n",
    "    prompt = [\n",
    "        SystemMessage(content=\"Create 3 questions from the passage that the user provides.\")\n",
    "    ] + state['messages']\n",
    "\n",
    "    response = model.invoke(prompt)\n",
    "\n",
    "    return {'messages': AIMessage(content=response.content, name=\"Bot\")}\n",
    "\n",
    "# The third node in the chain \n",
    "def answer_questions(state: MessagesState):\n",
    "    \"\"\" \n",
    "        This tool is usually called right after the generate_questions tool. Make sure the passage is given by the user before calling this tool. \n",
    "        Ask the user to provide the passage first if you do not find the passage in the conversation. \n",
    "\n",
    "        Receiving the state of the graph as input.\n",
    "    \"\"\"\n",
    "    prompt = [\n",
    "        SystemMessage(content=\"Answer all questions that you previously created based on the passage that the user provides. Format your response in pairs of Question and Answers\")\n",
    "    ] + state['messages']\n",
    "\n",
    "    response = model.invoke(prompt)\n",
    "\n",
    "    return {'messages': AIMessage(content=response.content, name=\"Bot\")}\n",
    "\n",
    "builder = StateGraph(MessagesState)\n",
    "builder.add_node(\"summarize_node\", summarize)\n",
    "builder.add_node(\"generate_question_node\", generate_questions)\n",
    "builder.add_node(\"answer_question_node\", answer_questions)\n",
    "builder.add_edge(START, \"summarize_node\")\n",
    "builder.add_edge(\"summarize_node\", \"generate_question_node\")\n",
    "builder.add_edge(\"generate_question_node\", \"answer_question_node\")\n",
    "builder.add_edge(\"answer_question_node\", END)\n",
    "graph = builder.compile()\n",
    "\n",
    "# user prompt\n",
    "prompt = HumanMessage(content=input_text, name=\"Hizkia\")\n",
    "graph_output = graph.invoke({\"messages\": prompt})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea85258",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_output['messages'][-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3645ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in graph_output['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f08ea45",
   "metadata": {},
   "source": [
    "## Agents with Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c07cadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tools \n",
    "tools = [summarize, generate_questions, answer_questions]\n",
    "model_with_tools = model.bind_tools(tools)\n",
    "\n",
    "# Create Assistant Node\n",
    "\n",
    "def assistant(state: MessagesState):\n",
    "\n",
    "    sys_msg = SystemMessage(content=\"You are a helpful assistant who communicates with the user and decide what the user intends to do. \\n\" \\\n",
    "                            \"When the user says greeting, reponds the greeting politely and introduce yourself as Dexa Smart Assistant.\\n\" \\\n",
    "                            \"When the user instructs you to summarize a passage, ask user to give the passage first, then call the summarize tool.\\n\" \\\n",
    "                            \"When the user asks you to generate questions, ask the user to give you the passage, then call the generate_questions and answer_questions tools sequentially\" \\\n",
    "                            \"When the passage exists in the chat history, directly call the tools.\")\n",
    "    \n",
    "    return {'messages': [model_with_tools.invoke([sys_msg] + state['messages'])]}\n",
    "\n",
    "# Build the graph \n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "builder = StateGraph(MessagesState)\n",
    "\n",
    "# Define nodes\n",
    "builder.add_node(\"assistant\", assistant)\n",
    "builder.add_node(\"tools\", ToolNode(tools))\n",
    "\n",
    "# Define edges \n",
    "builder.add_edge(START, \"assistant\")\n",
    "builder.add_conditional_edges(\n",
    "    \"assistant\",\n",
    "    tools_condition\n",
    ")\n",
    "builder.add_edge(\"tools\", \"assistant\")\n",
    "react_graph = builder.compile()\n",
    "\n",
    "# Show graph \n",
    "display(Image(react_graph.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628b4120",
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "graph_output = react_graph.invoke({'messages': HumanMessage(content=\"Hi, good morning.\")})\n",
    "# graph_output = react_graph.invoke({'messages': HumanMessage(content=\"Help me summarize a passage.\")})\n",
    "# graph_output = react_graph.invoke({'messages': HumanMessage(content=input_text)})\n",
    "# graph_output = react_graph.invoke({'messages': HumanMessage(content=\"I want to summarize the passage.\")})\n",
    "graph_output\n",
    "\n",
    "### \n",
    "# In the end the assistant does not call any tool because it does not remember the whole conversation. Let's add a memory to the graph so it remembers the conversation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b698c5b",
   "metadata": {},
   "source": [
    "## Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59cf6adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "memory = MemorySaver()\n",
    "\n",
    "react_graph_memory = builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da152c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify a thread \n",
    "config = {\"configurable\": {\"thread_id\" : \"1\"}}\n",
    "\n",
    "# specify an input \n",
    "# messages = HumanMessage(content=\"Hi, good afternoon.\")\n",
    "# messages = HumanMessage(content=\"Help me summarize a passage.\")\n",
    "# messages = HumanMessage(content=input_text) \n",
    "# messages = HumanMessage(content=\"Great! Now can u generate quesions out of it?\")\n",
    "# messages = HumanMessage(content=\"you can use the previous passage.\") \n",
    "messages = HumanMessage(content=\"Now, provide also the answer to those questions.\")\n",
    "\n",
    "# Run \n",
    "messages = react_graph_memory.invoke({\"messages\": messages}, config)\n",
    "for m in messages['messages']: \n",
    "    m.pretty_print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13f8d75",
   "metadata": {},
   "source": [
    "# Prebuilt ReAct Agent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7cddba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "\n",
    "memory2 = InMemorySaver()\n",
    "agent = create_react_agent(\n",
    "    model=\"openai:gpt-4.1-mini\",  \n",
    "    tools=[summarize, generate_questions, answer_questions],  \n",
    "    prompt=\"You are a helpful assistant who communicates with the user and decide what the user intends to do. \\n\" \\\n",
    "            \"When the user says greeting, reponds the greeting politely and introduce yourself as Dexa Smart Assistant.\\n\" \\\n",
    "            \"When the user instructs you to summarize a passage, ask user to give the passage first, then call the summarize tool.\\n\" \\\n",
    "            \"When the user asks you to generate questions, ask the user to give you the passage, then call the generate_questions and answer_questions tools sequentially\" \\\n",
    "            \"When the passage exists in the chat history, directly call the tools.\",\n",
    "    checkpointer=memory2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e940ae79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the agent\n",
    "config = {\"configurable\": {\"thread_id\" : \"2\"}}\n",
    "# agent.invoke({\"messages\": HumanMessage(content=\"Hi, good evening.\")},config=config)\n",
    "# agent.invoke({\"messages\": HumanMessage(content=f\"Can you help me summarize the following passage: {input_text}\")},config=config)\n",
    "# agent.invoke({\"messages\": HumanMessage(content=\"Please generate questions from the passage.\")},config=config)\n",
    "# agent.invoke({\"messages\": HumanMessage(content=\"Yes, you are correct.\")},config=config)\n",
    "agent.invoke({\"messages\": HumanMessage(content=\"Dont forget to generate the anwer of those questions\")},config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff233d15",
   "metadata": {},
   "source": [
    "## (Bonus) Streaming the graph response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94984ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread \n",
    "config = {\"configurable\": {\"thread_id\" : \"1\"}}\n",
    "\n",
    "# Start the conversation \n",
    "async for event in react_graph_memory.astream_events({\"messages\": [HumanMessage(content=\"Hi, what have we been talking about?\")]}, config=config, version=\"v2\"):\n",
    "    if event[\"event\"] == \"on_chat_model_stream\":\n",
    "        print(event[\"data\"]['chunk'].content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a0024d",
   "metadata": {},
   "source": [
    "# END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
