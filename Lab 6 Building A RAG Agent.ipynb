{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16656aaf",
   "metadata": {},
   "source": [
    "# Lab 6: Building A RAG Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f37baa",
   "metadata": {},
   "source": [
    "## Setup Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c4ed0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load Environment Table\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)  # take environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4cdad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load large language model \n",
    "from langchain.chat_models import init_chat_model\n",
    "llm = init_chat_model(\"gpt-4.1-nano\", model_provider=\"openai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a6d7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install langchain_huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650bc0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting Embedding model\n",
    "# from langchain_openai import OpenAIEmbeddings\n",
    "# embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "# embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"intfloat/multilingual-e5-large-instruct\")\n",
    "# embedding_model = HuggingFaceEmbeddings(model_name=\"Alibaba-NLP/gte-Qwen2-7B-instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c041bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from langchain_openai import OpenAIEmbeddings\n",
    "#embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b899173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate Vector Code\n",
    "# In-memory \n",
    "\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "vector_store = InMemoryVectorStore(embedding_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96c86b1",
   "metadata": {},
   "source": [
    "## Document Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7d8068",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qU pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb387498",
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "file_path = \"./docs/Tentang Dexa Medica.pdf\"\n",
    "\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(file_path)\n",
    "pages = []\n",
    "async for page in loader.alazy_load():\n",
    "    pages.append(page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44e1b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{pages[0].metadata}\\n\")\n",
    "print(pages[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a3c150",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = loader.load()\n",
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01848a38",
   "metadata": {},
   "source": [
    "## Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd6f9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500, chunk_overlap=100\n",
    ")\n",
    "\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "\n",
    "len(all_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88582c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "for split in all_splits:\n",
    "    print(split)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61afdca",
   "metadata": {},
   "source": [
    "## Embedding and Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d20f59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store.add_documents(all_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fa6f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store.similarity_search(\"siapa pendiri Dexa Medica\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb956f7",
   "metadata": {},
   "source": [
    "## Defining Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c24e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool(response_format=\"content_and_artifact\")\n",
    "def retrieve(query: str):\n",
    "    \"\"\"Retrieve information related to a query.\"\"\"\n",
    "    retrieved_docs = vector_store.similarity_search(query, k=5)\n",
    "    serialized = \"\\n\\n\".join(\n",
    "        (f\"Source: {doc.metadata}\\n\" f\"Content: {doc.page_content}\")\n",
    "        for doc in retrieved_docs\n",
    "    )\n",
    "    return serialized, retrieved_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7439272",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import MessagesState, StateGraph\n",
    "from langchain_core.messages import SystemMessage\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "\n",
    "# Step 1: Generate an AIMessage that may include a tool-call to be sent.\n",
    "def query_or_respond(state: MessagesState):\n",
    "    \"\"\"Generate tool call for retrieval or respond.\"\"\"\n",
    "    llm_with_tools = llm.bind_tools([retrieve])\n",
    "    response = llm_with_tools.invoke(state[\"messages\"])\n",
    "    # MessagesState appends messages to state instead of overwriting\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "# Step 2: Execute the retrieval.\n",
    "tools = ToolNode([retrieve])\n",
    "\n",
    "\n",
    "# Step 3: Generate a response using the retrieved content.\n",
    "def generate(state: MessagesState):\n",
    "    \"\"\"Generate answer.\"\"\"\n",
    "    # Get generated ToolMessages\n",
    "    recent_tool_messages = []\n",
    "    for message in reversed(state[\"messages\"]):\n",
    "        if message.type == \"tool\":\n",
    "            recent_tool_messages.append(message)\n",
    "        else:\n",
    "            break\n",
    "    tool_messages = recent_tool_messages[::-1]\n",
    "\n",
    "    # Format into prompt\n",
    "    docs_content = \"\\n\\n\".join(doc.content for doc in tool_messages)\n",
    "    system_message_content = (\n",
    "        \"You are an assistant for question-answering tasks. \"\n",
    "        \"Use the following pieces of retrieved context to answer \"\n",
    "        \"the question. If you don't know the answer, say that you \"\n",
    "        \"don't know. Keep the answer concise.\"\n",
    "        \"\\n\\n\"\n",
    "        f\"{docs_content}\"\n",
    "    )\n",
    "    conversation_messages = [\n",
    "        message\n",
    "        for message in state[\"messages\"]\n",
    "        if message.type in (\"human\", \"system\")\n",
    "        or (message.type == \"ai\" and not message.tool_calls)\n",
    "    ]\n",
    "    prompt = [SystemMessage(system_message_content)] + conversation_messages\n",
    "\n",
    "    # Run\n",
    "    response = llm.invoke(prompt)\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2bcbe68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "graph_builder = StateGraph(MessagesState)\n",
    "graph_builder.add_node(query_or_respond)\n",
    "graph_builder.add_node(tools)\n",
    "graph_builder.add_node(generate)\n",
    "\n",
    "graph_builder.set_entry_point(\"query_or_respond\")\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"query_or_respond\",\n",
    "    tools_condition,\n",
    "    {END: END, \"tools\": \"tools\"},\n",
    ")\n",
    "graph_builder.add_edge(\"tools\", \"generate\")\n",
    "graph_builder.add_edge(\"generate\", END)\n",
    "\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5779ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aef92c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_message = \"Hello\"\n",
    "\n",
    "for step in graph.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": input_message}]},\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe56c817",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "input_message = \"Siapa pendiri Dexa Medica?\"\n",
    "\n",
    "for step in graph.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": input_message}]},\n",
    "    stream_mode=\"values\",\n",
    "    config=config,\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5848a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_message = \"dimana Dexa Medica didirikan?\"\n",
    "\n",
    "for step in graph.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": input_message}]},\n",
    "    stream_mode=\"values\",\n",
    "    config=config,\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0876a814",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_message = \"Sebutkan 4 kompetensi inti yang dimiliki Dexa Medica.\"\n",
    "\n",
    "for step in graph.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": input_message}]},\n",
    "    stream_mode=\"values\",\n",
    "    config=config,\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b8ba4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_message = \"Apa saja kontribusi yang sudah dilakukan oleh Dexa Medica?\"\n",
    "\n",
    "for step in graph.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": input_message}]},\n",
    "    stream_mode=\"values\",\n",
    "    config=config,\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bec0148",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_message = \"Carikan informasi tentang Dexa Medica. Meliputi Motto, lokasi, dan pendiri.\"\n",
    "\n",
    "for step in graph.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": input_message}]},\n",
    "    stream_mode=\"values\",\n",
    "    config=config,\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89533a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "memory = MemorySaver()\n",
    "graph = graph_builder.compile(checkpointer=memory)\n",
    "\n",
    "# Specify an ID for the thread\n",
    "config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "\n",
    "input_message = \"sebutkan visi dan misi Dexa Medica\"\n",
    "\n",
    "for step in graph.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": input_message}]},\n",
    "    stream_mode=\"values\",\n",
    "    config=config,\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a6cf87",
   "metadata": {},
   "source": [
    "### Check Similarity Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9e33a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store.similarity_search(\"sebutkan visi dan misi Dexa Medica\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4071ae",
   "metadata": {},
   "source": [
    "# END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
